{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_file import *\n",
    "from utils.split_law import split_law_to_token\n",
    "from utils.model_tool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = read_json(QUESTION_PATH)[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 下載模型到指定路徑\n",
    "# local_model_path = \"./models/bge-m3\"\n",
    "# snapshot_download(repo_id=\"BAAI/bge-m3\", revision=\"main\", local_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加載模型\n",
    "embbeded_model = SentenceTransformer(\"./models/bge-m3\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_faq(embbeded_model, question):\n",
    "    faq = read_json(FAQ_PATH)\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    for i in range(100, 150):\n",
    "        document = read_target_faq(faq, question[i][\"source\"])\n",
    "        k_highest, _ = get_ans(embbeded_model, question[i], document)\n",
    "        predict = question[i][\"source\"][k_highest[0]]\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(f\"qid: {i + 1}, predict: {predict}, ans: {ans[\"ground_truths\"][i][\"retrieve\"]}\")\n",
    "    return correct / 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證faq資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 109, predict: 234, ans: 283\n",
      "qid: 135, predict: 399, ans: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_faq(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NUM = 2000\n",
    "\n",
    "def validate_insurance(embbeded_model, question):\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    half_correct = 0 #答案在前五\n",
    "\n",
    "    already_read = [\"\" for _ in range(FILE_NUM)]\n",
    "\n",
    "\n",
    "    for i in range(0, 50):\n",
    "        src = np.array(question[i][\"source\"])\n",
    "        document = read_target_insurance_pdf(INSURANCE_PATH, src, already_read)\n",
    "        tokens = []\n",
    "        chunk_real_index = []\n",
    "        for j in range(len(document)):\n",
    "            text = document[j]\n",
    "\n",
    "            if already_read[src[j]] == \"\":\n",
    "                already_read[src[j]] = text\n",
    "\n",
    "            chunks = split_law_to_token(text)\n",
    "            tokens.extend(chunks)\n",
    "            chunk_real_index.extend([j + k * 0 for k in range(len(chunks))])\n",
    "\n",
    "                \n",
    "        chunk_real_index = np.array(chunk_real_index)\n",
    "\n",
    "        k = 10\n",
    "        token_index, similarities = get_ans(embbeded_model, question[i], tokens, k)\n",
    "        real_index = chunk_real_index[token_index]\n",
    "        all_predict = src[real_index]\n",
    "        predict = all_predict[0]\n",
    "\n",
    "\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            show_wrong_ans(i, predict, ans, token_index, \\\n",
    "                   src, real_index, similarities, chunk_real_index, tokens, \"output_insurance\")\n",
    "\n",
    "\n",
    "        if (ans[\"ground_truths\"][i][\"retrieve\"] in all_predict):\n",
    "            half_correct += 1\n",
    "\n",
    "    print(f\"acc: {correct / 50 * 100} %\")\n",
    "    print(f\"in rank 5: {half_correct / 50 * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證insurance資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 2, predict: 258, ans: 428\n",
      "qid: 4, predict: 179, ans: 186\n",
      "qid: 50, predict: 555, ans: 78\n",
      "acc: 94.0 %\n",
      "in rank 5: 96.0 %\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"output_insurance/\"):\n",
    "    os.makedirs(\"output_insurance/\")\n",
    "\n",
    "validate_insurance(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
