{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_file import read_target_insurance_pdf, read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = read_json(QUESTION_PATH)[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files:  60%|██████    | 18/30 [00:20<00:00, 18.21it/s]Error while downloading from https://cdn-lfs-us-1.hf.co/repos/23/2c/232ca60237b0bb19bb6c28c5a6c8af79f2e423333a9626aad445543b80fbf31e/1eebfb28493f67bba03ce0ef64bfdc7fc5a3bd9d7493f818bb1d78cd798416b4?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.onnx_data%3B+filename%3D%22model.onnx_data%22%3B&Expires=1730383139&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDM4MzEzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzIzLzJjLzIzMmNhNjAyMzdiMGJiMTliYjZjMjhjNWE2YzhhZjc5ZjJlNDIzMzMzYTk2MjZhYWQ0NDU1NDNiODBmYmYzMWUvMWVlYmZiMjg0OTNmNjdiYmEwM2NlMGVmNjRiZmRjN2ZjNWEzYmQ5ZDc0OTNmODE4YmIxZDc4Y2Q3OTg0MTZiND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KuJxdKvDF1Ax%7EM2lJF2SbVuF-09w%7ENR5p-O3mmBM2%7EJ5tufv44RmwqpPukths-l0tggTFLWr9uuREcaid7uxjQWnABtOtnEUpeoqCG8MvjM7odZC00jqUBA1yz25OUzDyi%7EzwJ8dEF8KO8Qbd3f%7Eg5fmxe7-gMqdnug5j0hz-RWfvkeeddth0cHGOYvM3eI3EeUJ-5qeWpbMp%7EsHcGjn7evke5bPWh7cJu4D9oPDqcWD8wCxYn-yn%7E892V5sf0ns8bux5FFmNLm6FsDHRRcausI08DiwEs8w22ryHX%7EhEqsJq6aherFWzSWe3gbBrgu9omw-g-qRkRFpR8YC4Ds5NA__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 30 files: 100%|██████████| 30/30 [03:04<00:00,  6.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\weiso131\\\\Desktop\\\\AI cup 玉山銀行\\\\models\\\\bge-m3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 下載模型到指定路徑\n",
    "# local_model_path = \"./models/bge-m3\"\n",
    "# snapshot_download(repo_id=\"BAAI/bge-m3\", revision=\"main\", local_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加載模型\n",
    "embbeded_model = SentenceTransformer(\"./models/bge-m3\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_ans(embedded_model, question_data: dict, documents: list, k=1):\n",
    "    document_ebeddings = embedded_model.encode(documents)\n",
    "\n",
    "    # 使用者查詢\n",
    "    user_query = question_data[\"query\"]\n",
    "\n",
    "    # 查詢文本轉換成嵌入向量\n",
    "    query_embedding = embbeded_model.encode([user_query])\n",
    "\n",
    "    # 計算相似度\n",
    "    similarities = cosine_similarity(query_embedding, document_ebeddings)\n",
    "    k_highest = np.argsort(similarities[0])[-k:][::-1]\n",
    "    return k_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_faq_retrieve(faq: dict, id: int) -> str:\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    for faq_data in faq[str(id)]:\n",
    "\n",
    "        question = faq_data[\"question\"]\n",
    "        answers = faq_data[\"answers\"]\n",
    "        text += f\"問題:{question}, 回答:{answers}\\n\"\n",
    "    return text\n",
    "\n",
    "def read_target_faq(faq: dict, indexs: list) -> list:\n",
    "\n",
    "    all_texts = []\n",
    "\n",
    "    for i in indexs:\n",
    "        all_texts.append(generate_faq_retrieve(faq, i))\n",
    "    \n",
    "    return all_texts\n",
    "\n",
    "\n",
    "def validate_faq(embbeded_model, question):\n",
    "    faq = read_json(FAQ_PATH)\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    for i in range(100, 150):\n",
    "        document = read_target_faq(faq, question[i][\"source\"])\n",
    "        predict = question[i][\"source\"][get_ans(embbeded_model, question[i], document)[0]]\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(f\"qid: {i + 1}, predict: {predict}, ans: {ans[\"ground_truths\"][i][\"retrieve\"]}\")\n",
    "    return correct / 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證faq資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 109, predict: 234, ans: 283\n",
      "qid: 135, predict: 399, ans: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_faq(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  # 每段的目標長度\n",
    "    chunk_overlap=400  # 分段間的重疊字符數\n",
    ")\n",
    "\n",
    "def validate_insurance(embbeded_model, question):\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    for i in range(0, 50):\n",
    "        src = question[i][\"source\"]\n",
    "        document, order_list = read_target_insurance_pdf(INSURANCE_PATH, src)\n",
    "        tokens = []\n",
    "        chunk_real_index = []\n",
    "        for j in range(len(document)):\n",
    "            text = document[j]\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            tokens.extend(chunks)\n",
    "            chunk_real_index.extend([j + k * 0 for k in range(len(chunks))])\n",
    "\n",
    "                \n",
    "        chunk_real_index=np.array(chunk_real_index)\n",
    "\n",
    "        token_index = get_ans(embbeded_model, question[i], tokens, 5)\n",
    "        real_index = chunk_real_index[token_index]\n",
    "        predict = order_list[real_index[0]]\n",
    "\n",
    "\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(f\"qid: {i + 1}, predict: {predict}, ans: {ans[\"ground_truths\"][i][\"retrieve\"]}\")\n",
    "            for index in token_index:\n",
    "                print(order_list[chunk_real_index[index]])\n",
    "            #print(tokens[token_index[0]])\n",
    "    return correct / 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證insurance資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 2, predict: 258, ans: 428\n",
      "258\n",
      "258\n",
      "565\n",
      "606\n",
      "475\n",
      "qid: 3, predict: 476, ans: 83\n",
      "476\n",
      "83\n",
      "83\n",
      "83\n",
      "179\n",
      "qid: 4, predict: 179, ans: 186\n",
      "179\n",
      "186\n",
      "627\n",
      "627\n",
      "627\n",
      "qid: 6, predict: 242, ans: 116\n",
      "242\n",
      "275\n",
      "116\n",
      "116\n",
      "275\n",
      "qid: 15, predict: 526, ans: 536\n",
      "526\n",
      "476\n",
      "337\n",
      "182\n",
      "182\n",
      "qid: 23, predict: 228, ans: 224\n",
      "228\n",
      "428\n",
      "228\n",
      "99\n",
      "428\n",
      "qid: 28, predict: 78, ans: 298\n",
      "78\n",
      "298\n",
      "298\n",
      "258\n",
      "506\n",
      "qid: 29, predict: 256, ans: 578\n",
      "256\n",
      "524\n",
      "102\n",
      "431\n",
      "524\n",
      "qid: 35, predict: 224, ans: 319\n",
      "224\n",
      "502\n",
      "319\n",
      "224\n",
      "283\n",
      "qid: 42, predict: 445, ans: 325\n",
      "445\n",
      "325\n",
      "188\n",
      "445\n",
      "568\n",
      "qid: 49, predict: 357, ans: 482\n",
      "357\n",
      "482\n",
      "580\n",
      "51\n",
      "482\n",
      "qid: 50, predict: 555, ans: 78\n",
      "555\n",
      "341\n",
      "555\n",
      "555\n",
      "528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_insurance(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
