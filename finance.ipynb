{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_file import *\n",
    "from utils.model_tool import *\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from utils.query_handler import extract_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\"\n",
    "FINANCE_PATH = \"競賽資料集/reference/finance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = read_json(QUESTION_PATH)[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba.analyse\n",
    "\n",
    "\n",
    "def find_most_correct(top10: list[str], query: str, all_predict, similarity: np.array):\n",
    "    keywords = jieba.analyse.extract_tags(query, topK=10)\n",
    "    score = list(np.zeros(len(top10)))\n",
    "    for i in range(len(top10)):\n",
    "        \n",
    "        for k in keywords:\n",
    "            if k.isdigit():\n",
    "                continue\n",
    "            if re.search(k, top10[i]):\n",
    "                score[i] += 1\n",
    "        score[i] *= similarity[i]\n",
    "    order = np.argsort(score)[::-1]\n",
    "    return all_predict[order[0]]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "chinese_num = ['○', '一', '二', '三', '四', '五', '六', '七', '八', '九']\n",
    "\n",
    "def get_years(time_data: list[int]):\n",
    "    years = []\n",
    "    for year in time_data[0]:\n",
    "        years.append(year)\n",
    "        char_count = 0\n",
    "        chinese_year = \"\"\n",
    "        while year[char_count] != '年':\n",
    "            chinese_year += chinese_num[int(year[char_count])]\n",
    "            char_count += 1\n",
    "        years.append(chinese_year + '年')\n",
    "    return years\n",
    "\n",
    "def get_valid_chunk(chunks: list[str], years: list[str]) -> list:\n",
    "    valid_chunks = []\n",
    "\n",
    "\n",
    "    pattern = r\"|\".join(years)\n",
    "    for chunk in chunks:\n",
    "        if re.search(pattern, chunk):\n",
    "            valid_chunks.append(chunk)\n",
    "\n",
    "    return valid_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"三—'重大或有負債及未認列之合約承諾\\n除已於其他附註所述者外，合併公司於資產負債表日重大未認列\\n之合約事項如下：\\n111年9月30日110年12月31日110年9月30日\\n購置不動產、廠房及設備$1$1$1\\n三二'具重大影響之外幣資產及負債資訊\\n以下資訊係按合併公司各個體功能性貨幣以外之外幣彙總表達，\\n所揭露之匯率係指該等外幣換算至功能性貨幣之匯率。具重大影響之\\n外幣資產及負債如下：\\n111年9月30日\\n外幣匯率帳面金額\\n金融資產\\n貨幣性項目\\n美金$11（美金：人民幣）$1\\n美金11（美金：新台幣）1\\n人民幣1,11（人民幣:新台幣）1\\n金融負債\\n貨帶性項目\\n美金11（美金：人民幣）1\\n美金11（美金：新台幣）1\\n人民幣11（人民幣:新台幣）1\\n110年12月31日\\n外幣匯率帳面金額\\n金融資產\\n貨幣性項目\\n美金$11（美金：人民幣）$1\\n美金11（美金：新台幣）1\\n人民幣11（人民幣：新台幣）1\\n金融負債\\n貨幣性項目\\n美金11（美金：人民幣）1\\n美金11（美金：新台幣）1\\n人民幣11（人民幣：新台幣）1\\n1-\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_read = [\"\" for _ in range(10000)]\n",
    "\n",
    "text = read_target_insurance_pdf(FINANCE_PATH, [10], already_read)[0]\n",
    "\n",
    "def remove_useless(text):\n",
    "\n",
    "    pattern = r\"(\\b\\d{1,3}(,\\d{3})+\\b)|(-?\\b\\d+(\\.\\d+)?\\b)\"\n",
    "    text = re.sub(pattern, '1', text)\n",
    "    text = str(text).replace(' ', '')\n",
    "    return text\n",
    "\n",
    "remove_useless(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 下載模型到指定路徑\n",
    "# local_model_path = \"./models/bge-m3\"\n",
    "# snapshot_download(repo_id=\"BAAI/bge-m3\", revision=\"main\", local_dir=local_model_path)\n",
    "\n",
    "\n",
    "# from transformers import AutoModel\n",
    "\n",
    "# reranker_model = 'BAAI/bge-reranker-v2-m3'\n",
    "\n",
    "# # 下載並儲存模型和 tokenizer 到本地\n",
    "# model_path = './local_bge_reranker_model'\n",
    "# model = AutoModel.from_pretrained(reranker_model)\n",
    "\n",
    "# # 將模型和 tokenizer 儲存到本地目錄\n",
    "# model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加載模型\n",
    "embbeded_model = SentenceTransformer(\"./models/bge-m3\", device='cuda')\n",
    "\n",
    "#reranker = FlagReranker('BAAI/bge-reranker-v2-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 每段的目標長度\n",
    "    chunk_overlap=300  # 分段間的重疊字符數\n",
    ")\n",
    "\n",
    "FILE_NUM = 2000\n",
    "\n",
    "def validate_finance(embbeded_model, question):\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    half_correct = 0 #答案在前五\n",
    "\n",
    "    already_read = [\"\" for _ in range(FILE_NUM)]\n",
    "\n",
    "    for i in range(50, 100):\n",
    "        query = question[i][\"query\"]\n",
    "\n",
    "\n",
    "        src = np.array(question[i][\"source\"])\n",
    "        document = read_target_insurance_pdf(FINANCE_PATH, src, already_read)\n",
    "        tokens = []\n",
    "        chunk_real_index = []\n",
    "\n",
    "\n",
    "        for j in range(len(document)):\n",
    "            text = remove_useless(document[j])\n",
    "\n",
    "\n",
    "            valid_chunks = text_splitter.split_text(text)\n",
    "\n",
    "            tokens.extend(valid_chunks)\n",
    "            chunk_real_index.extend([j + k * 0 for k in range(len(valid_chunks))])\n",
    "\n",
    "        \n",
    "        chunk_real_index = np.array(chunk_real_index)\n",
    "\n",
    "\n",
    "        token_index, similarities = get_ans(embbeded_model, question[i], tokens, 10)\n",
    "        real_index = chunk_real_index[token_index]\n",
    "        all_predict = src[real_index]\n",
    "        all_predict_text = [tokens[p] for p in token_index]\n",
    "        predict = find_most_correct(all_predict_text, query, all_predict, similarities)\n",
    "\n",
    "\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            show_wrong_ans(i, predict, ans, token_index, \\\n",
    "                   src, real_index, similarities, chunk_real_index, tokens, \"output_finance\")\n",
    "\n",
    "        if (ans[\"ground_truths\"][i][\"retrieve\"] in all_predict):\n",
    "            half_correct += 1\n",
    "\n",
    "    print(f\"acc: {correct / 50 * 100} %\")\n",
    "    print(f\"in rank 5: {half_correct / 50 * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證finance資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\weiso131\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.446 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 59, predict: 639, ans: 632\n",
      "qid: 64, predict: 706, ans: 124\n",
      "qid: 72, predict: 497, ans: 204\n",
      "qid: 80, predict: 386, ans: 213\n",
      "qid: 86, predict: 757, ans: 189\n",
      "qid: 94, predict: 481, ans: 699\n",
      "qid: 97, predict: 579, ans: 282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_finance/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_finance/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mvalidate_finance\u001b[49m\u001b[43m(\u001b[49m\u001b[43membbeded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m, in \u001b[0;36mvalidate_finance\u001b[1;34m(embbeded_model, question)\u001b[0m\n\u001b[0;32m     32\u001b[0m     chunk_real_index\u001b[38;5;241m.\u001b[39mextend([j \u001b[38;5;241m+\u001b[39m k \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(valid_chunks))])\n\u001b[0;32m     35\u001b[0m chunk_real_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(chunk_real_index)\n\u001b[1;32m---> 38\u001b[0m token_index, similarities \u001b[38;5;241m=\u001b[39m \u001b[43mget_ans\u001b[49m\u001b[43m(\u001b[49m\u001b[43membbeded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m real_index \u001b[38;5;241m=\u001b[39m chunk_real_index[token_index]\n\u001b[0;32m     40\u001b[0m all_predict \u001b[38;5;241m=\u001b[39m src[real_index]\n",
      "File \u001b[1;32mc:\\Users\\weiso131\\Desktop\\AI cup 玉山銀行\\utils\\model_tool.py:5\u001b[0m, in \u001b[0;36mget_ans\u001b[1;34m(embedded_model, question_data, documents, k)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ans\u001b[39m(embedded_model, question_data: \u001b[38;5;28mdict\u001b[39m, documents: \u001b[38;5;28mlist\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     document_ebeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 使用者查詢\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m question_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\weiso131\\anaconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:630\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 630\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    634\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"output_finance/\"):\n",
    "    os.makedirs(\"output_finance/\")\n",
    "validate_finance(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
