{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_file import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\"\n",
    "FINANCE_PATH = \"競賽資料集/reference/finance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = read_json(QUESTION_PATH)[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 下載模型到指定路徑\n",
    "# local_model_path = \"./models/bge-m3\"\n",
    "# snapshot_download(repo_id=\"BAAI/bge-m3\", revision=\"main\", local_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加載模型\n",
    "embbeded_model = SentenceTransformer(\"./models/bge-m3\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_ans(embedded_model, question_data: dict, documents: list, k=1):\n",
    "    document_ebeddings = embedded_model.encode(documents)\n",
    "\n",
    "    # 使用者查詢\n",
    "    user_query = question_data[\"query\"]\n",
    "\n",
    "    # 查詢文本轉換成嵌入向量\n",
    "    query_embedding = embbeded_model.encode([user_query])\n",
    "\n",
    "    # 計算相似度\n",
    "    similarities = cosine_similarity(query_embedding, document_ebeddings)\n",
    "    k_highest = np.argsort(similarities[0])[-k:][::-1]\n",
    "    return k_highest, similarities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證faq資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 每段的目標長度\n",
    "    chunk_overlap=300  # 分段間的重疊字符數\n",
    ")\n",
    "\n",
    "\n",
    "def validate_finance(embbeded_model, question):\n",
    "    ans = read_json(ANS_PATH)\n",
    "    correct = 0\n",
    "    half_correct = 0 #答案在前五\n",
    "\n",
    "    for i in range(50, 100):\n",
    "        src = question[i][\"source\"]\n",
    "        document, order_list = read_target_insurance_pdf(FINANCE_PATH, src)\n",
    "        tokens = []\n",
    "        chunk_real_index = []\n",
    "        for j in range(len(document)):\n",
    "            text = document[j]\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            tokens.extend(chunks)\n",
    "            chunk_real_index.extend([j + k * 0 for k in range(len(chunks))])\n",
    "\n",
    "                \n",
    "        chunk_real_index=np.array(chunk_real_index)\n",
    "\n",
    "\n",
    "        token_index, similarities = get_ans(embbeded_model, question[i], tokens, 10)\n",
    "        real_index = chunk_real_index[token_index]\n",
    "        all_predict = order_list[real_index]\n",
    "        predict = all_predict[0]\n",
    "\n",
    "\n",
    "        if (predict == ans[\"ground_truths\"][i][\"retrieve\"]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(f\"qid: {i + 1}, predict: {predict}, ans: {ans[\"ground_truths\"][i][\"retrieve\"]}\")\n",
    "            chunks_text = f\"qid: {i + 1}, ans:{ans[\"ground_truths\"][i][\"retrieve\"]}\\n\\n\\n\"\n",
    "\n",
    "            for j in range(len(token_index)):\n",
    "                chunks_text += f\"index: {order_list[real_index[j]]}, similarity: {similarities[token_index[j]]}\\n\\n{tokens[token_index[j]]}\\n\\n\\n\"\n",
    "\n",
    "            chunks_text += f\"正確答案{ans[\"ground_truths\"][i][\"retrieve\"]}的token\\n\"\n",
    "            for j in range(len(tokens)):\n",
    "                \n",
    "                if order_list[chunk_real_index[j]] == ans[\"ground_truths\"][i][\"retrieve\"]:\n",
    "                    chunks_text += f\"token:{j + 1}, similarity: {similarities[j]}\\n\\n{tokens[j]}\\n\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "            with open(f\"output_finance/qid_{i + 1}.txt\", 'w', encoding='utf-8') as file:\n",
    "                file.write(chunks_text)\n",
    "        if (ans[\"ground_truths\"][i][\"retrieve\"] in all_predict):\n",
    "            half_correct += 1\n",
    "\n",
    "    print(f\"acc: {correct / 50 * 100} %\")\n",
    "    print(f\"in rank 5: {half_correct / 50 * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證finance資料集的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"output_finance/\"):\n",
    "    os.makedirs(\"output_finance/\")\n",
    "validate_finance(embbeded_model, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
