{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from utils.read_file import *\n",
    "from utils.model_tool import get_ans, use_reranker\n",
    "from utils.split_law import split_law_to_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\"\n",
    "FINANCE_PATH = \"競賽資料集/reference/finance\"\n",
    "FILE_NUM = 2000\n",
    "\n",
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "QUESTION_PATH = \"questions_preliminary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weiso131\\anaconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# 加載模型\n",
    "embbeded_model = SentenceTransformer(\"./models/bge-m3\", device='cuda')\n",
    "#reranker = FlagReranker('BAAI/bge-reranker-v2-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_predictions_to_json(predictions, filename=\"pred_retrieve.json\"):#Modified\n",
    "    output = {\"answers\": predictions}\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Predictions saved to {filename}\")\n",
    "\n",
    "def gernerate_faq_ans(embbeded_model, question, i: int):\n",
    "    faq = read_json(FAQ_PATH)\n",
    "    document = read_target_faq(faq, question[i][\"source\"])\n",
    "    k_highest, _ = get_ans(embbeded_model, question[i], document)\n",
    "    predict = question[i][\"source\"][k_highest[0]]\n",
    "    \n",
    "    return predict\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def gernerate_insurance_ans(embedded_model, question, i: int, already_read: list[str]):\n",
    "\n",
    "    src = np.array(question[i][\"source\"])\n",
    "    document = read_target_insurance_pdf(INSURANCE_PATH, src, already_read)\n",
    "    tokens = []\n",
    "    chunk_real_index = []\n",
    "\n",
    "    for j in range(len(document)):\n",
    "        chunks = split_law_to_token(document[j])\n",
    "        tokens.extend(chunks)\n",
    "        chunk_real_index.extend([src[j] for k in range(len(chunks))])\n",
    "\n",
    "    chunk_real_index = np.array(chunk_real_index)\n",
    "    token_index, _ = get_ans(embedded_model, question[i], tokens, 10)\n",
    "    all_predict = chunk_real_index[token_index]\n",
    "    #all_predict_text = [tokens[ti] for ti in token_index]\n",
    "    predict = all_predict[0]\n",
    "\n",
    "    return predict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba.analyse\n",
    "def remove_useless(text):\n",
    "\n",
    "    pattern = r\"(\\b\\d{1,3}(,\\d{3})+\\b)|(-?\\b\\d+(\\.\\d+)?\\b)\"\n",
    "    text = re.sub(pattern, '1', text)\n",
    "    text = str(text).replace(' ', '')\n",
    "    return text\n",
    "\n",
    "def find_most_correct(top10: list[str], query: str, all_predict, similarity: np.array):\n",
    "    keywords = jieba.analyse.extract_tags(query, topK=10)\n",
    "    score = list(np.zeros(len(top10)))\n",
    "    for i in range(len(top10)):\n",
    "        \n",
    "        for k in keywords:\n",
    "            if k.isdigit():\n",
    "                continue\n",
    "            if re.search(k, top10[i]):\n",
    "                score[i] += 1\n",
    "        score[i] *= similarity[i]\n",
    "    order = np.argsort(score)[::-1]\n",
    "    return all_predict[order[0]]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 每段的目標長度\n",
    "    chunk_overlap=300  # 分段間的重疊字符數\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gernerate_finance_ans(embbeded_model, question, i: int, already_read: list[str]):\n",
    "\n",
    "    query = question[i][\"query\"]\n",
    "\n",
    "\n",
    "    src = np.array(question[i][\"source\"])\n",
    "    document = read_target_insurance_pdf(FINANCE_PATH, src, already_read)\n",
    "    tokens = []\n",
    "    chunk_real_index = []\n",
    "\n",
    "\n",
    "    for j in range(len(document)):\n",
    "        text = remove_useless(document[j])\n",
    "        valid_chunks = text_splitter.split_text(text)\n",
    "        tokens.extend(valid_chunks)\n",
    "        chunk_real_index.extend([src[j] for k in range(len(valid_chunks))])\n",
    "\n",
    "    \n",
    "    chunk_real_index = np.array(chunk_real_index)\n",
    "\n",
    "    token_index, similarities = get_ans(embbeded_model, question[i], tokens, 10)\n",
    "    all_predict = chunk_real_index[token_index]\n",
    "    all_predict_text = [tokens[p] for p in token_index]\n",
    "    predict = find_most_correct(all_predict_text, query, all_predict, similarities)\n",
    "\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "already_read_insurance = [\"\" for _ in range(FILE_NUM)]\n",
    "already_read_finance = [\"\" for _ in range(FILE_NUM)]\n",
    "\n",
    "question = read_json(QUESTION_PATH)[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\weiso131\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.468 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(question)):\n",
    "    category = question[i]['category']\n",
    "    predict = 0\n",
    "    if category == \"insurance\":\n",
    "        predict = gernerate_insurance_ans(embbeded_model, question, i, already_read_insurance)\n",
    "    elif category == \"finance\":\n",
    "        predict = gernerate_finance_ans(embbeded_model, question, i, already_read_finance)\n",
    "    elif category == \"faq\":\n",
    "        predict = gernerate_faq_ans(embbeded_model, question, i)\n",
    "    results.append({\"qid\": i + 1, \"retrieve\": int(predict)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to pred_retrieve.json\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_json(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid: 2, predict: 258, ans: 428\n",
      "qid: 4, predict: 179, ans: 186\n",
      "qid: 50, predict: 555, ans: 78\n",
      "qid: 59, predict: 639, ans: 632\n",
      "qid: 64, predict: 706, ans: 124\n",
      "qid: 72, predict: 497, ans: 204\n",
      "qid: 80, predict: 386, ans: 213\n",
      "qid: 86, predict: 757, ans: 189\n",
      "qid: 94, predict: 481, ans: 699\n",
      "qid: 97, predict: 579, ans: 282\n",
      "qid: 109, predict: 234, ans: 283\n",
      "qid: 135, predict: 399, ans: 28\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "\n",
    "# ans = read_json(ANS_PATH)['ground_truths']\n",
    "# pred_retrieve = read_json('pred_retrieve.json')['answers']\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for i in range(len(ans)):\n",
    "#     if ans[i]['retrieve'] != pred_retrieve[i]['retrieve']:\n",
    "#         print(f\"qid: {i + 1}, predict: {pred_retrieve[i]['retrieve']}, ans: {ans[i]['retrieve']}\")\n",
    "#     else:\n",
    "#         correct += 1\n",
    "#     total += 1\n",
    "# print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
