{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from utils.read_file import *\n",
    "from utils.model_tool import get_ans\n",
    "from utils.split_law import split_law_to_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PATH = \"競賽資料集/dataset/preliminary/questions_example.json\"\n",
    "\n",
    "INSURANCE_PATH = \"競賽資料集/reference/insurance\"\n",
    "FAQ_PATH = \"競賽資料集/reference/faq/pid_map_content.json\"\n",
    "ANS_PATH = \"競賽資料集/dataset/preliminary/ground_truths_example.json\"\n",
    "FINANCE_PATH = \"競賽資料集/reference/finance\"\n",
    "FILE_NUM = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_predictions_to_json(predictions, filename=\"pred_retrieve.json\"):#Modified\n",
    "    output = {\"answers\": predictions}\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Predictions saved to {filename}\")\n",
    "\n",
    "def gernerate_faq_ans(embbeded_model, question, i: int, results: list):\n",
    "    faq = read_json(FAQ_PATH)\n",
    "    document = read_target_faq(faq, question[i][\"source\"])\n",
    "    k_highest, _ = get_ans(embbeded_model, question[i], document)\n",
    "    predict = question[i][\"source\"][k_highest[0]]\n",
    "    results.append({\"qid\": i + 1, \"retrieve\": predict})  # Modified\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def gernerate_insurance_ans(embedded_model, question, i: int, results: list):\n",
    "\n",
    "    already_read = [\"\" for _ in range(FILE_NUM)]\n",
    "\n",
    "    src = np.array(question[i][\"source\"])\n",
    "    document = read_target_insurance_pdf(INSURANCE_PATH, src, already_read)\n",
    "    tokens = []\n",
    "    chunk_real_index = []\n",
    "\n",
    "    for j in range(len(document)):\n",
    "        chunks = split_law_to_token(document[j])\n",
    "        tokens.extend(chunks)\n",
    "        chunk_real_index.extend([src[j] for k in range(len(chunks))])\n",
    "\n",
    "    chunk_real_index = np.array(chunk_real_index)\n",
    "    token_index, _ = get_ans(embedded_model, question[i], tokens, 10)\n",
    "    all_predict = chunk_real_index[token_index]\n",
    "\n",
    "    predict = all_predict[0]\n",
    "\n",
    "    results.append({\"qid\": i + 1, \"retrieve\": predict})  #modified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "save_predictions_to_json(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
